En este trabajo nos encontramos con 4 modelos diferentes:

1. Un agente que trabaja y entrena usando la tecnica del DQN
   Carpeta: DQN
   Ejecucion: python3 tetris.py

2. Un agente que trabaja y entrena usando la tecnica A3C
   Carpeta: A3C
   Ejecucion: python3 A3C.py

3. Un agente que siempre calcula el mejor estado posible, sin mejora alguna
   Carpeta: CHOOSE
   Ejecucion: python3 tetris_choose.py

4. Un agente que mezcla los agentes 1 y 3
   Carpeta: COMBINE
   Ejecucion: python3 tetris_combine.py


